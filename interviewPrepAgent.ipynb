{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "489512fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import asyncio\n",
    "\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dac2e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "except ImportError:\n",
    "    raise ImportError(\"Run: pip install nest-asyncio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79d0ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from agents import Agent, Runner, function_tool\n",
    "except ImportError:\n",
    "    raise ImportError(\"Run: pip install openai-agents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3231ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d7a3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = os.getenv(\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b868abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_AGENTS_DISABLE_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2afecbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openrouter_client = AsyncOpenAI(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:7860\",\n",
    "        \"X-Title\": \"Interview Prep Agent\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b5969f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb4debbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to use â€” swap to any OpenRouter model ID you like, e.g.:\n",
    "#   \"openai/gpt-4o\"\n",
    "#   \"anthropic/claude-3.5-sonnet\"\n",
    "#   \"mistralai/mixtral-8x7b-instruct\"\n",
    "#   \"meta-llama/llama-3.1-70b-instruct\"\n",
    "MODEL = \"meta-llama/llama-3.1-70b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70a35ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Question Bank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "QUESTION_BANK: dict[str, dict[str, list[str]]] = {\n",
    "    \"Python Developer\": {\n",
    "        \"Technical\": [\n",
    "            \"Explain the difference between *args and **kwargs.\",\n",
    "            \"What is the GIL and how does it affect multithreading?\",\n",
    "            \"How does Python's memory management and garbage collection work?\",\n",
    "            \"What are decorators and how do you create a custom one?\",\n",
    "            \"Explain list comprehensions vs generator expressions.\",\n",
    "            \"What is the difference between deepcopy and shallow copy?\",\n",
    "            \"How does Python handle exceptions? Explain try/except/else/finally.\",\n",
    "            \"What are context managers and how do you implement __enter__/__exit__?\",\n",
    "            \"Explain the difference between @staticmethod and @classmethod.\",\n",
    "            \"What are metaclasses in Python?\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Describe a time you debugged a particularly tricky Python issue.\",\n",
    "            \"How do you keep up with new Python features and ecosystem changes?\",\n",
    "            \"Tell me about a project where you improved Python code performance.\",\n",
    "            \"How do you approach code reviews â€” giving and receiving feedback?\",\n",
    "            \"Describe your strategy for writing maintainable, testable code.\",\n",
    "        ],\n",
    "    },\n",
    "    \"Data Analyst\": {\n",
    "        \"Technical\": [\n",
    "            \"Explain the difference between INNER JOIN, LEFT JOIN, and FULL OUTER JOIN.\",\n",
    "            \"How would you handle missing or null data in a dataset?\",\n",
    "            \"What is the difference between correlation and causation?\",\n",
    "            \"How would you detect and handle outliers in a dataset?\",\n",
    "            \"What is a p-value and how do you interpret statistical significance?\",\n",
    "            \"How would you design a dashboard for non-technical stakeholders?\",\n",
    "            \"What are window functions in SQL? Give a practical example.\",\n",
    "            \"How do you validate the accuracy and quality of your analysis?\",\n",
    "            \"What is the difference between variance and standard deviation?\",\n",
    "            \"Explain normalization vs denormalization in database design.\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Tell me about a time your analysis directly influenced a business decision.\",\n",
    "            \"How do you explain complex data findings to non-technical audiences?\",\n",
    "            \"Describe a situation where you discovered an unexpected insight.\",\n",
    "            \"How do you prioritize when given multiple analysis requests at once?\",\n",
    "            \"Tell me about a time you caught a significant error in an analysis.\",\n",
    "        ],\n",
    "    },\n",
    "    \"Project Manager\": {\n",
    "        \"Technical\": [\n",
    "            \"What is the difference between Agile, Scrum, and Waterfall?\",\n",
    "            \"How do you build and maintain a project risk register?\",\n",
    "            \"Explain the critical path method in project scheduling.\",\n",
    "            \"How do you define and track KPIs for a project?\",\n",
    "            \"What tools do you use for project tracking and why?\",\n",
    "            \"How do you manage scope creep effectively?\",\n",
    "            \"What is earned value management (EVM) and how do you use it?\",\n",
    "            \"How do you structure a work breakdown structure (WBS)?\",\n",
    "            \"Explain the difference between a milestone and a deliverable.\",\n",
    "            \"How do you manage task dependencies across teams?\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Tell me about a project that failed and what you learned from it.\",\n",
    "            \"How do you handle conflict between team members?\",\n",
    "            \"Describe a time you had to deliver difficult news to a stakeholder.\",\n",
    "            \"How do you keep a team motivated when behind schedule?\",\n",
    "            \"Tell me about managing competing priorities across multiple projects.\",\n",
    "        ],\n",
    "    },\n",
    "    \"Frontend Developer\": {\n",
    "        \"Technical\": [\n",
    "            \"Explain the difference between CSS Flexbox and CSS Grid.\",\n",
    "            \"What is the virtual DOM and how does React use it?\",\n",
    "            \"How does event delegation work in JavaScript?\",\n",
    "            \"What are closures in JavaScript and why are they useful?\",\n",
    "            \"Explain the difference between == and === in JavaScript.\",\n",
    "            \"What is CORS and how do you handle it on the frontend?\",\n",
    "            \"Explain the browser's critical rendering path.\",\n",
    "            \"What are Web Workers and when should you use them?\",\n",
    "            \"What is tree shaking and how does it improve bundle size?\",\n",
    "            \"Explain the difference between SSR, CSR, and SSG.\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Tell me about a challenging UI component you built.\",\n",
    "            \"How do you balance design fidelity vs development speed?\",\n",
    "            \"Describe a time you significantly improved page load performance.\",\n",
    "            \"How do you ensure accessibility in your frontend work?\",\n",
    "            \"Tell me about a time you disagreed with a designer's decision.\",\n",
    "        ],\n",
    "    },\n",
    "    \"Machine Learning Engineer\": {\n",
    "        \"Technical\": [\n",
    "            \"Explain the bias-variance tradeoff.\",\n",
    "            \"What is the difference between bagging and boosting?\",\n",
    "            \"How do you handle class imbalance in training data?\",\n",
    "            \"Explain gradient descent and its main variants (SGD, Adam, RMSProp).\",\n",
    "            \"What is the difference between L1 and L2 regularization?\",\n",
    "            \"What is k-fold cross-validation and why is it important?\",\n",
    "            \"How would you deploy and monitor a machine learning model in production?\",\n",
    "            \"What is feature engineering and why does it matter?\",\n",
    "            \"Explain the attention mechanism in transformer architectures.\",\n",
    "            \"What is the curse of dimensionality?\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Tell me about a model that performed well in training but failed in production.\",\n",
    "            \"How do you explain ML model decisions to non-technical stakeholders?\",\n",
    "            \"Describe your process for selecting a model architecture for a new problem.\",\n",
    "            \"Tell me about a time you had to work with very messy, real-world data.\",\n",
    "            \"How do you stay current with ML research and new techniques?\",\n",
    "        ],\n",
    "    },\n",
    "    \"DevOps Engineer\": {\n",
    "        \"Technical\": [\n",
    "            \"Explain the key differences between containers and virtual machines.\",\n",
    "            \"What is a CI/CD pipeline and how would you design one from scratch?\",\n",
    "            \"How does Kubernetes handle service discovery and load balancing?\",\n",
    "            \"What is infrastructure as code? Compare Terraform vs Ansible.\",\n",
    "            \"Explain blue-green deployments vs canary deployments.\",\n",
    "            \"How do you manage secrets in a cloud-native environment?\",\n",
    "            \"What is the difference between horizontal and vertical scaling?\",\n",
    "            \"How would you set up observability (logs, metrics, traces) for a service?\",\n",
    "            \"Explain how a load balancer works and the types available.\",\n",
    "            \"What are the main differences between AWS, GCP, and Azure?\",\n",
    "        ],\n",
    "        \"Behavioral\": [\n",
    "            \"Tell me about a major production outage you responded to.\",\n",
    "            \"How do you build a culture of reliability and operational excellence?\",\n",
    "            \"Describe a significant manual process you automated.\",\n",
    "            \"How do you handle pushback when enforcing security or compliance policies?\",\n",
    "            \"Tell me about a deployment that went wrong and how you recovered.\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21186784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = list(QUESTION_BANK.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9119c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ In-memory session store (keyed by a simple session id) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Each session: {\"scores\": [], \"asked\": set(), \"role\": str}\n",
    "_SESSIONS: dict[str, dict] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d1dab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_question(session_id: str, role: str, category: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch a fresh interview question for the given role and category.\n",
    "    Avoids repeating questions already asked in this session.\n",
    "\n",
    "    Args:\n",
    "        session_id: Unique ID for this interview session.\n",
    "        role:       Job role (e.g. 'Python Developer').\n",
    "        category:   'Technical' or 'Behavioral'.\n",
    "    Returns:\n",
    "        A question string.\n",
    "    \"\"\"\n",
    "    if session_id not in _SESSIONS:\n",
    "        _SESSIONS[session_id] = {\"scores\": [], \"asked\": set(), \"role\": role}\n",
    "\n",
    "    bank = QUESTION_BANK.get(role, {}).get(category, [])\n",
    "    asked = _SESSIONS[session_id][\"asked\"]\n",
    "    available = [q for q in bank if q not in asked] or bank  # reset if exhausted\n",
    "\n",
    "    question = random.choice(available)\n",
    "    _SESSIONS[session_id][\"asked\"].add(question)\n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6016eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def record_score(session_id: str, score: int) -> str:\n",
    "    \"\"\"\n",
    "    Save a score (1â€“5) to the session tracker.\n",
    "\n",
    "    Args:\n",
    "        session_id: Unique ID for this interview session.\n",
    "        score:      Integer 1 (poor) to 5 (excellent).\n",
    "    Returns:\n",
    "        Confirmation with running stats.\n",
    "    \"\"\"\n",
    "    if session_id not in _SESSIONS:\n",
    "        _SESSIONS[session_id] = {\"scores\": [], \"asked\": set(), \"role\": \"\"}\n",
    "\n",
    "    _SESSIONS[session_id][\"scores\"].append(max(1, min(5, score)))\n",
    "    scores = _SESSIONS[session_id][\"scores\"]\n",
    "    avg = sum(scores) / len(scores)\n",
    "    return f\"Recorded {score}/5. Total: {len(scores)} answers, avg: {avg:.1f}/5.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93e2f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_session_summary(session_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Return full performance summary for the session.\n",
    "\n",
    "    Args:\n",
    "        session_id: Unique ID for this interview session.\n",
    "    Returns:\n",
    "        JSON with scores, average, count, and performance label.\n",
    "    \"\"\"\n",
    "    session = _SESSIONS.get(session_id)\n",
    "    if not session or not session[\"scores\"]:\n",
    "        return json.dumps({\"error\": \"No scores recorded yet.\"})\n",
    "\n",
    "    scores = session[\"scores\"]\n",
    "    avg = sum(scores) / len(scores)\n",
    "    label = (\n",
    "        \"Excellent\" if avg >= 4.5 else\n",
    "        \"Great \"     if avg >= 3.5 else\n",
    "        \"Good \"      if avg >= 2.5 else\n",
    "        \"Fair \"      if avg >= 1.5 else\n",
    "        \"Needs Work\"\n",
    "    )\n",
    "    return json.dumps({\n",
    "        \"scores\":          scores,\n",
    "        \"average\":         round(avg, 2),\n",
    "        \"total_questions\": len(scores),\n",
    "        \"performance\":     label,\n",
    "        \"role\":            session.get(\"role\", \"\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f75db1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"You are an Interview Coach conducting mock interviews.\n",
    "\n",
    "TOOLS AVAILABLE:\n",
    "- get_question(session_id, role, category): gets next interview question\n",
    "- record_score(session_id, score): saves score 1-5\n",
    "- get_session_summary(session_id): gets final stats\n",
    "\n",
    "RULES â€” follow exactly:\n",
    "\n",
    "On SESSION START (user gives role + session_id):\n",
    "  1. Call get_question(session_id=<id>, role=<role>, category=\"Technical\")\n",
    "  2. Output ONLY this, nothing else:\n",
    "  QUESTION: <the question text>\n",
    "  QNUM: 1\n",
    "  CATEGORY: Technical\n",
    "\n",
    "On receiving an ANSWER:\n",
    "  1. Score it 1-5. Call record_score(session_id=<id>, score=<n>)\n",
    "  2. Call get_question for next question (alternate Technical/Behavioral)\n",
    "  3. Output ONLY this, nothing else:\n",
    "  SCORE: <1-5>\n",
    "  STRENGTHS: <one sentence on what was good>\n",
    "  IMPROVE: <one sentence on what to improve>\n",
    "  IDEAL: <model answer in 2-3 sentences>\n",
    "  QUESTION: <next question text>\n",
    "  QNUM: <next number>\n",
    "  CATEGORY: <Technical or Behavioral>\n",
    "\n",
    "On STOP/QUIT/END:\n",
    "  1. Call get_session_summary(session_id=<id>)\n",
    "  2. Output ONLY this:\n",
    "  SUMMARY: <encouraging 2-sentence summary>\n",
    "  AVG: <average score>\n",
    "  TOTAL: <number of questions>\n",
    "\n",
    "Never add extra text. Never use JSON. Use the exact format above.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0622757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent() -> Agent:\n",
    "    return Agent(\n",
    "        name=\"InterviewCoach\",\n",
    "        instructions=INSTRUCTIONS,\n",
    "        tools=[get_question, record_score, get_session_summary],\n",
    "        model=OpenAIChatCompletionsModel(\n",
    "            model=MODEL,\n",
    "            openai_client=openrouter_client,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c525ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_sync(agent: Agent, history: list[dict], user_msg: str) -> tuple[str, list[dict]]:\n",
    "    \"\"\"\n",
    "    Run one agent turn synchronously.\n",
    "    Works in both Jupyter (patched by nest_asyncio) and Gradio worker threads\n",
    "    (which have no event loop â€” we create a fresh one for them).\n",
    "    \"\"\"\n",
    "    history = history + [{\"role\": \"user\", \"content\": user_msg}]\n",
    "\n",
    "    async def _run():\n",
    "        return await Runner.run(agent, input=history)\n",
    "\n",
    "    try:\n",
    "        # Try getting existing loop first (works in Jupyter main thread)\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_closed():\n",
    "            raise RuntimeError(\"Loop is closed\")\n",
    "        result = loop.run_until_complete(_run())\n",
    "    except RuntimeError:\n",
    "        # No event loop in this thread (Gradio worker thread) â€” create a new one\n",
    "        result = asyncio.run(_run())\n",
    "\n",
    "    reply = result.final_output\n",
    "    return reply, history + [{\"role\": \"assistant\", \"content\": reply}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3aae0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_field(text: str, key: str) -> str:\n",
    "    \"\"\"Extract a field value from the plain-text format: KEY: value\"\"\"\n",
    "    for line in text.splitlines():\n",
    "        if line.strip().upper().startswith(key.upper() + \":\"):\n",
    "            return line.split(\":\", 1)[1].strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64dfc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_agent_reply(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse agent reply in plain KEY: value format.\n",
    "    Returns a dict with 'type' set to 'question', 'feedback', or 'summary'.\n",
    "    \"\"\"\n",
    "    t = text.strip()\n",
    "    has = lambda k: any(l.strip().upper().startswith(k+\":\") for l in t.splitlines())\n",
    "\n",
    "    if has(\"SUMMARY\") or has(\"AVG\"):\n",
    "        try:\n",
    "            avg = float(_get_field(t, \"AVG\") or 0)\n",
    "        except ValueError:\n",
    "            avg = 0.0\n",
    "        try:\n",
    "            total = int(_get_field(t, \"TOTAL\") or 0)\n",
    "        except ValueError:\n",
    "            total = 0\n",
    "        return {\n",
    "            \"type\": \"summary\",\n",
    "            \"message\": _get_field(t, \"SUMMARY\"),\n",
    "            \"average_score\": avg,\n",
    "            \"total_questions\": total,\n",
    "            \"performance\": (\n",
    "                \"Excellent ğŸŒŸ\" if avg >= 4.5 else\n",
    "                \"Great ğŸ‘\"     if avg >= 3.5 else\n",
    "                \"Good âœ…\"      if avg >= 2.5 else\n",
    "                \"Fair ğŸ“ˆ\"      if avg >= 1.5 else\n",
    "                \"Needs Work ğŸ’ª\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    if has(\"SCORE\") and has(\"QUESTION\"):\n",
    "        try:\n",
    "            score = int(_get_field(t, \"SCORE\") or 3)\n",
    "        except ValueError:\n",
    "            score = 3\n",
    "        try:\n",
    "            qnum = int(_get_field(t, \"QNUM\") or 1)\n",
    "        except ValueError:\n",
    "            qnum = 1\n",
    "        return {\n",
    "            \"type\": \"feedback_and_question\",\n",
    "            \"score\": max(1, min(5, score)),\n",
    "            \"strengths\":    _get_field(t, \"STRENGTHS\"),\n",
    "            \"improvements\": _get_field(t, \"IMPROVE\"),\n",
    "            \"ideal_answer\": _get_field(t, \"IDEAL\"),\n",
    "            \"question\":     _get_field(t, \"QUESTION\"),\n",
    "            \"question_number\": qnum,\n",
    "            \"category\":     _get_field(t, \"CATEGORY\") or \"Technical\",\n",
    "        }\n",
    "\n",
    "    if has(\"QUESTION\"):\n",
    "        try:\n",
    "            qnum = int(_get_field(t, \"QNUM\") or 1)\n",
    "        except ValueError:\n",
    "            qnum = 1\n",
    "        return {\n",
    "            \"type\": \"question\",\n",
    "            \"question\": _get_field(t, \"QUESTION\"),\n",
    "            \"question_number\": qnum,\n",
    "            \"category\": _get_field(t, \"CATEGORY\") or \"Technical\",\n",
    "        }\n",
    "\n",
    "    # Fallback: return raw text as a question display\n",
    "    return {\"type\": \"raw\", \"text\": t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "907fd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_feedback(p: dict) -> str:\n",
    "    score = p.get(\"score\", 0)\n",
    "    stars = \"â­\" * score + \"â˜†\" * (5 - score)\n",
    "    return (\n",
    "        f\"### ğŸ“Š Score: {score}/5  {stars}\\n\\n\"\n",
    "        f\"**âœ… Strengths**\\n{p.get('strengths', 'â€”')}\\n\\n\"\n",
    "        f\"**ğŸ”§ Areas to Improve**\\n{p.get('improvements', 'â€”')}\\n\\n\"\n",
    "        f\"**ğŸ’¡ Ideal Answer**\\n> {p.get('ideal_answer', 'â€”')}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba9d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_question(p: dict) -> str:\n",
    "    badge = \"ğŸ”µ Technical\" if p.get(\"category\") == \"Technical\" else \"ğŸŸ£ Behavioral\"\n",
    "    return (\n",
    "        f\"**{badge}  |  Question {p.get('question_number', '?')}**\\n\\n\"\n",
    "        f\"### ğŸ’¬ {p.get('question', '')}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30d25727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_summary(p: dict) -> str:\n",
    "    avg = p.get(\"average_score\", 0)\n",
    "    filled = min(5, round(avg))\n",
    "    stars = \"â­\" * filled + \"â˜†\" * (5 - filled)\n",
    "    return (\n",
    "        f\"## ğŸ‰ Session Complete!  {stars}\\n\\n\"\n",
    "        f\"**Score: {avg:.1f} / 5.0** â€” *{p.get('performance', '')}*\\n\\n\"\n",
    "        f\"**Questions answered:** {p.get('total_questions', 0)}\\n\\n\"\n",
    "        f\"{p.get('message', '')}\\n\\n---\\n\"\n",
    "        f\"*Click **New Session** to practice again!*\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eeaad910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GRADIO HANDLERS\n",
    "def start_interview(role, agent_state, api_history, session_id, scores):\n",
    "    if not role:\n",
    "        return (\n",
    "            \"âš ï¸ Please select a role first.\", \"\",\n",
    "            agent_state, api_history, session_id, scores,\n",
    "            gr.update(interactive=False), gr.update(interactive=True),\n",
    "        )\n",
    "    try:\n",
    "        sid = str(uuid.uuid4())[:8]\n",
    "        agent = build_agent()\n",
    "        raw, api_history = run_agent_sync(\n",
    "            agent, [],\n",
    "            f\"Start a {role} interview. My session_id is '{sid}'.\"\n",
    "        )\n",
    "        parsed = parse_agent_reply(raw)\n",
    "        if parsed[\"type\"] == \"question\":\n",
    "            question_md = fmt_question(parsed)\n",
    "        else:\n",
    "            question_md = f\"### ğŸ’¬ {parsed.get('question', raw)}\"\n",
    "        status = f\"ğŸ¯ **{role}**  |  Questions: **0**  |  Avg: **â€”**\"\n",
    "        return (\n",
    "            question_md, status,\n",
    "            agent, api_history, sid, [],\n",
    "            gr.update(interactive=True),\n",
    "            gr.update(interactive=False),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"âŒ **Error starting session:**\\n```\\n{e}\\n```\", \"\",\n",
    "            agent_state, api_history, session_id, scores,\n",
    "            gr.update(interactive=False), gr.update(interactive=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c326be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_answer(answer, agent_state, api_history, session_id, scores, chat_history):\n",
    "    if not answer.strip():\n",
    "        return chat_history, \"\", agent_state, api_history, session_id, scores, \"\", \"\"\n",
    "\n",
    "    is_stop = any(w in answer.lower() for w in {\"stop\", \"quit\", \"exit\", \"end\"})\n",
    "\n",
    "    # Gradio 6.6 requires dict messages: {\"role\": ..., \"content\": ...}\n",
    "    chat_history = chat_history + [{\"role\": \"user\", \"content\": answer}]\n",
    "\n",
    "    try:\n",
    "        raw, api_history = run_agent_sync(\n",
    "            agent_state, api_history,\n",
    "            \"end session\" if is_stop else answer\n",
    "        )\n",
    "    except Exception as e:\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": f\"âŒ Agent error:\\n```\\n{e}\\n```\"})\n",
    "        return chat_history, \"\", agent_state, api_history, session_id, scores, \"\", \"\"\n",
    "\n",
    "    parsed = parse_agent_reply(raw)\n",
    "\n",
    "    # â”€â”€ End of session â”€â”€\n",
    "    if parsed[\"type\"] == \"summary\":\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": fmt_summary(parsed)})\n",
    "        avg = parsed.get(\"average_score\", 0)\n",
    "        return (chat_history, \"\", agent_state, api_history, session_id, scores,\n",
    "                f\"âœ… Done  |  Final avg: **{avg:.1f} / 5**\", \"\")\n",
    "\n",
    "    # â”€â”€ Feedback + next question (combined reply) â”€â”€\n",
    "    if parsed[\"type\"] == \"feedback_and_question\":\n",
    "        score = parsed.get(\"score\", 0)\n",
    "        scores = scores + [score]\n",
    "        avg = sum(scores) / len(scores)\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": fmt_feedback(parsed)})\n",
    "        status = f\"Questions: **{len(scores)}**  |  Avg: **{avg:.1f} / 5**\"\n",
    "        next_q_md = fmt_question(parsed)\n",
    "        return chat_history, \"\", agent_state, api_history, session_id, scores, status, next_q_md\n",
    "\n",
    "    # â”€â”€ Raw / unrecognised response â€” show it so we can debug â”€â”€\n",
    "    bot_text = parsed.get(\"text\", raw) or \"âš ï¸ No response parsed.\"\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": bot_text})\n",
    "    return chat_history, \"\", agent_state, api_history, session_id, scores, \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c73f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_session():\n",
    "    return (\n",
    "        [],   # chatbot â€” empty list, Gradio 6.6 handles dict format automatically\n",
    "        None, [], \"\", [],\n",
    "        \"*Select a role and click Start Interview.*\",\n",
    "        \"*Your question will appear here...*\",\n",
    "        gr.update(interactive=True),\n",
    "        gr.update(interactive=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56761e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GRADIO UI\n",
    "CSS = \"\"\"\n",
    "#question-box {\n",
    "    border-left: 4px solid #38bdf8;\n",
    "    border-radius: 8px;\n",
    "    padding: 14px;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(title=\"ğŸ¯ Interview Prep Agent\") as demo:\n",
    "\n",
    "    agent_state       = gr.State(None)\n",
    "    api_history_state = gr.State([])\n",
    "    session_id_state  = gr.State(\"\")\n",
    "    scores_state      = gr.State([])\n",
    "\n",
    "    gr.Markdown(\"# ğŸ¯ Interview Preparation Agent\")\n",
    "    gr.Markdown(\n",
    "        \"AI-powered mock interviews Â· real-time scoring Â· coaching feedback  \\n\"\n",
    "        f\"**Stack:** OpenAI Agents SDK + OpenRouter (free tier) + Gradio {gr.__version__}\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### âš™ï¸ Setup\")\n",
    "            role_dropdown = gr.Dropdown(\n",
    "                choices=ROLES, label=\"Select Job Role\", value=None, interactive=True\n",
    "            )\n",
    "            start_btn = gr.Button(\"ğŸš€ Start Interview\", variant=\"primary\")\n",
    "            reset_btn = gr.Button(\"ğŸ”„ New Session\",     variant=\"secondary\")\n",
    "\n",
    "            gr.Markdown(\"---\")\n",
    "            gr.Markdown(\"### ğŸ› ï¸ Agent Tools\")\n",
    "            gr.Markdown(\n",
    "                \"**ğŸ“š get_question** â€” draws from curated bank, no repeats\\n\\n\"\n",
    "                \"**ğŸ“Š record_score** â€” persists scores per session\\n\\n\"\n",
    "                \"**ğŸ“‹ get_session_summary** â€” final performance report\"\n",
    "            )\n",
    "            gr.Markdown(\"---\")\n",
    "            gr.Markdown(\"### Score Guide\")\n",
    "            gr.Markdown(\n",
    "                \"**1** â€” Poor  \\n **2** â€” Fair  \\n\"\n",
    "                \"**3** â€” Good  \\n**4** â€” Great  \\n\"\n",
    "                \"**5** â€” Excellent\"\n",
    "            )\n",
    "\n",
    "        with gr.Column(scale=3):\n",
    "            status_bar       = gr.Markdown(\"*Select a role and click Start Interview.*\")\n",
    "            current_question = gr.Markdown(\n",
    "                \"*Your question will appear here...*\", elem_id=\"question-box\"\n",
    "            )\n",
    "            chatbot = gr.Chatbot(label=\"Interview Session\", height=400)\n",
    "\n",
    "            with gr.Row():\n",
    "                answer_box = gr.Textbox(\n",
    "                    placeholder=\"Type your answer... (Enter to submit, Shift+Enter for newline)\",\n",
    "                    label=\"Your Answer\",\n",
    "                    lines=3,\n",
    "                    interactive=False,\n",
    "                    scale=4,\n",
    "                )\n",
    "                submit_btn = gr.Button(\"Submit â¤\", variant=\"primary\", scale=1)\n",
    "\n",
    "    # â”€â”€ Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    start_btn.click(\n",
    "        fn=start_interview,\n",
    "        inputs=[role_dropdown, agent_state, api_history_state,\n",
    "                session_id_state, scores_state],\n",
    "        outputs=[current_question, status_bar, agent_state, api_history_state,\n",
    "                 session_id_state, scores_state, answer_box, start_btn],\n",
    "    )\n",
    "\n",
    "    for trigger in [submit_btn.click, answer_box.submit]:\n",
    "        trigger(\n",
    "            fn=submit_answer,\n",
    "            inputs=[answer_box, agent_state, api_history_state,\n",
    "                    session_id_state, scores_state, chatbot],\n",
    "            outputs=[chatbot, answer_box, agent_state, api_history_state,\n",
    "                     session_id_state, scores_state, status_bar, current_question],\n",
    "        )\n",
    "\n",
    "    reset_btn.click(\n",
    "        fn=reset_session,\n",
    "        inputs=[],\n",
    "        outputs=[chatbot, agent_state, api_history_state, session_id_state,\n",
    "                 scores_state, status_bar, current_question, start_btn, answer_box],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51664bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "âœ… Gradio 6.6.0  |  Model: meta-llama/llama-3.1-70b-instruct\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# â”€â”€ Launch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    gr.close_all()\n",
    "    print(f\"âœ… Gradio {gr.__version__}  |  Model: {MODEL}\")\n",
    "    demo.launch(\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7860,\n",
    "        share=False,\n",
    "        show_error=True,\n",
    "        theme=gr.themes.Soft(),\n",
    "        css=CSS,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hassan (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
